{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a80099707/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/a80099707/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/a80099707/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/a80099707/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/a80099707/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/a80099707/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import metrics\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Add, Multiply\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('./data/20210421_trainXs_y1_y2.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>...</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "      <td>4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>...</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>...</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>...</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "      <td>5204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>...</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>...</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>...</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "      <td>7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>...</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "      <td>10040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>...</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "      <td>5096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>...</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "      <td>4486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>...</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>...</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>...</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "      <td>6782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>...</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "      <td>19295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>...</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>...</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "      <td>23767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9   \\\n",
       "51                                                                           \n",
       "1.0    4041   4041   4041   4041   4041   4041   4041   4041   4041   4041   \n",
       "2.0    1560   1560   1560   1560   1560   1560   1560   1560   1560   1560   \n",
       "3.0      72     72     72     72     72     72     72     72     72     72   \n",
       "4.0    2175   2175   2175   2175   2175   2175   2175   2175   2175   2175   \n",
       "5.0     146    146    146    146    146    146    146    146    146    146   \n",
       "6.0      34     34     34     34     34     34     34     34     34     34   \n",
       "7.0    5204   5204   5204   5204   5204   5204   5204   5204   5204   5204   \n",
       "8.0      84     84     84     84     84     84     84     84     84     84   \n",
       "9.0    4436   4436   4436   4436   4436   4436   4436   4436   4436   4436   \n",
       "10.0   1463   1463   1463   1463   1463   1463   1463   1463   1463   1463   \n",
       "12.0    386    386    386    386    386    386    386    386    386    386   \n",
       "13.0   7340   7340   7340   7340   7340   7340   7340   7340   7340   7340   \n",
       "14.0  10040  10040  10040  10040  10040  10040  10040  10040  10040  10040   \n",
       "16.0   5096   5096   5096   5096   5096   5096   5096   5096   5096   5096   \n",
       "17.0   4486   4486   4486   4486   4486   4486   4486   4486   4486   4486   \n",
       "18.0   1557   1557   1557   1557   1557   1557   1557   1557   1557   1557   \n",
       "20.0   1631   1631   1631   1631   1631   1631   1631   1631   1631   1631   \n",
       "21.0   6782   6782   6782   6782   6782   6782   6782   6782   6782   6782   \n",
       "22.0  19295  19295  19295  19295  19295  19295  19295  19295  19295  19295   \n",
       "23.0    405    405    405    405    405    405    405    405    405    405   \n",
       "24.0  23767  23767  23767  23767  23767  23767  23767  23767  23767  23767   \n",
       "\n",
       "      ...     41     42     43     44     45     46     47     48     49  \\\n",
       "51    ...                                                                  \n",
       "1.0   ...   4041   4041   4041   4041   4041   4041   4041   4041   4041   \n",
       "2.0   ...   1560   1560   1560   1560   1560   1560   1560   1560   1560   \n",
       "3.0   ...     72     72     72     72     72     72     72     72     72   \n",
       "4.0   ...   2175   2175   2175   2175   2175   2175   2175   2175   2175   \n",
       "5.0   ...    146    146    146    146    146    146    146    146    146   \n",
       "6.0   ...     34     34     34     34     34     34     34     34     34   \n",
       "7.0   ...   5204   5204   5204   5204   5204   5204   5204   5204   5204   \n",
       "8.0   ...     84     84     84     84     84     84     84     84     84   \n",
       "9.0   ...   4436   4436   4436   4436   4436   4436   4436   4436   4436   \n",
       "10.0  ...   1463   1463   1463   1463   1463   1463   1463   1463   1463   \n",
       "12.0  ...    386    386    386    386    386    386    386    386    386   \n",
       "13.0  ...   7340   7340   7340   7340   7340   7340   7340   7340   7340   \n",
       "14.0  ...  10040  10040  10040  10040  10040  10040  10040  10040  10040   \n",
       "16.0  ...   5096   5096   5096   5096   5096   5096   5096   5096   5096   \n",
       "17.0  ...   4486   4486   4486   4486   4486   4486   4486   4486   4486   \n",
       "18.0  ...   1557   1557   1557   1557   1557   1557   1557   1557   1557   \n",
       "20.0  ...   1631   1631   1631   1631   1631   1631   1631   1631   1631   \n",
       "21.0  ...   6782   6782   6782   6782   6782   6782   6782   6782   6782   \n",
       "22.0  ...  19295  19295  19295  19295  19295  19295  19295  19295  19295   \n",
       "23.0  ...    405    405    405    405    405    405    405    405    405   \n",
       "24.0  ...  23767  23767  23767  23767  23767  23767  23767  23767  23767   \n",
       "\n",
       "         50  \n",
       "51           \n",
       "1.0    4041  \n",
       "2.0    1560  \n",
       "3.0      72  \n",
       "4.0    2175  \n",
       "5.0     146  \n",
       "6.0      34  \n",
       "7.0    5204  \n",
       "8.0      84  \n",
       "9.0    4436  \n",
       "10.0   1463  \n",
       "12.0    386  \n",
       "13.0   7340  \n",
       "14.0  10040  \n",
       "16.0   5096  \n",
       "17.0   4486  \n",
       "18.0   1557  \n",
       "20.0   1631  \n",
       "21.0   6782  \n",
       "22.0  19295  \n",
       "23.0    405  \n",
       "24.0  23767  \n",
       "\n",
       "[21 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.groupby(by=51).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 개수\n",
    "FTR_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 25), (100000, 25), (100000,), (100000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = raw.iloc[:, :FTR_SIZE]\n",
    "X2 = raw.iloc[:, FTR_SIZE:-2]\n",
    "Y = raw.iloc[:, -2]\n",
    "Z = raw.iloc[:, -1]\n",
    "\n",
    "X1.shape, X2.shape, Y.shape, Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test, z_train, z_test = train_test_split(X1, X2, Y, Z, random_state=66, test_size=0.4)\n",
    "X1_val, X1_test, X2_val, X2_test, y_val, y_test, z_val, z_test = train_test_split(X1_test, X2_test, y_test, z_test, random_state=66, test_size=0.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 25)\n",
      "(16000, 25)\n",
      "(60000, 25)\n",
      "(16000, 25)\n",
      "(60000,)\n",
      "(16000,)\n",
      "(60000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "for item in [X1_train, X1_test, X2_train, X2_test, y_train, y_test, z_train, z_test]:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train, z_val, z_test = z_train.astype(int), z_val.astype(int), z_test.astype(int)\n",
    "z_train, z_val, z_test = z_train - 1, z_val - 1, z_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_avg = Input(shape=(FTR_SIZE,), name='input_cardsvcs_avg')\n",
    "input_max = Input(shape=(FTR_SIZE,), name='input_cardsvcs_max')\n",
    "\n",
    "input_out1 = Dense(32, activation='relu', name='hid_avg')(input_avg)\n",
    "input_out2 = Dense(32, activation='relu', name='hid_max')(input_max)\n",
    "\n",
    "concat1 = Concatenate(axis=1)([input_out1, input_out2])\n",
    "hidden3 = Dense(64, activation='relu', name='hid_concat1')(concat1)\n",
    "hidden_out = Dense(32, activation='relu', name='hid_concat2')(hidden3)\n",
    "\n",
    "output1 = Dense(1, name='cont_out')(hidden_out)  # 연회비\n",
    "output2 = Dense(FTR_SIZE-1, activation='softmax', name='cat_out')(hidden_out)  # 서비스 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_avg, input_max], outputs=[output1, output2])\n",
    "\n",
    "model.compile(loss={'cont_out': 'mean_absolute_error', \n",
    "                    'cat_out': 'sparse_categorical_crossentropy'}, # softmax_cross_entropy_with_logits_v2\n",
    "              optimizer='sgd',\n",
    "              metrics={#'cont_out': metrics.mae,\n",
    "                  'cat_out': 'sparse_categorical_accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 42s 692us/step - loss: 1.8485 - cont_out_loss: 0.1254 - cat_out_loss: 1.7231 - cat_out_sparse_categorical_accuracy: 0.4843 - val_loss: 1.3105 - val_cont_out_loss: 0.1109 - val_cat_out_loss: 1.1996 - val_cat_out_sparse_categorical_accuracy: 0.6084\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 1.1708 - cont_out_loss: 0.1230 - cat_out_loss: 1.0479 - cat_out_sparse_categorical_accuracy: 0.6400 - val_loss: 1.0325 - val_cont_out_loss: 0.0952 - val_cat_out_loss: 0.9374 - val_cat_out_sparse_categorical_accuracy: 0.6785\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 1.0013 - cont_out_loss: 0.1141 - cat_out_loss: 0.8872 - cat_out_sparse_categorical_accuracy: 0.6842 - val_loss: 0.9837 - val_cont_out_loss: 0.1462 - val_cat_out_loss: 0.8375 - val_cat_out_sparse_categorical_accuracy: 0.6952\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.9205 - cont_out_loss: 0.1087 - cat_out_loss: 0.8118 - cat_out_sparse_categorical_accuracy: 0.7047 - val_loss: 0.8897 - val_cont_out_loss: 0.0868 - val_cat_out_loss: 0.8029 - val_cat_out_sparse_categorical_accuracy: 0.7005\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.8706 - cont_out_loss: 0.1053 - cat_out_loss: 0.7653 - cat_out_sparse_categorical_accuracy: 0.7157 - val_loss: 0.8342 - val_cont_out_loss: 0.1026 - val_cat_out_loss: 0.7315 - val_cat_out_sparse_categorical_accuracy: 0.7318\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.8312 - cont_out_loss: 0.1012 - cat_out_loss: 0.7300 - cat_out_sparse_categorical_accuracy: 0.7273 - val_loss: 0.8006 - val_cont_out_loss: 0.0967 - val_cat_out_loss: 0.7039 - val_cat_out_sparse_categorical_accuracy: 0.7367\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.8006 - cont_out_loss: 0.0985 - cat_out_loss: 0.7021 - cat_out_sparse_categorical_accuracy: 0.7386 - val_loss: 0.7989 - val_cont_out_loss: 0.1190 - val_cat_out_loss: 0.6799 - val_cat_out_sparse_categorical_accuracy: 0.7494\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.7728 - cont_out_loss: 0.0946 - cat_out_loss: 0.6781 - cat_out_sparse_categorical_accuracy: 0.7486 - val_loss: 0.7391 - val_cont_out_loss: 0.0803 - val_cat_out_loss: 0.6588 - val_cat_out_sparse_categorical_accuracy: 0.7535\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.7507 - cont_out_loss: 0.0916 - cat_out_loss: 0.6590 - cat_out_sparse_categorical_accuracy: 0.7585 - val_loss: 0.7540 - val_cont_out_loss: 0.0967 - val_cat_out_loss: 0.6573 - val_cat_out_sparse_categorical_accuracy: 0.7577\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.7318 - cont_out_loss: 0.0894 - cat_out_loss: 0.6424 - cat_out_sparse_categorical_accuracy: 0.7647 - val_loss: 0.7286 - val_cont_out_loss: 0.0990 - val_cat_out_loss: 0.6296 - val_cat_out_sparse_categorical_accuracy: 0.7687\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.7145 - cont_out_loss: 0.0872 - cat_out_loss: 0.6273 - cat_out_sparse_categorical_accuracy: 0.7710 - val_loss: 0.6858 - val_cont_out_loss: 0.0752 - val_cat_out_loss: 0.6107 - val_cat_out_sparse_categorical_accuracy: 0.7748\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.6991 - cont_out_loss: 0.0849 - cat_out_loss: 0.6142 - cat_out_sparse_categorical_accuracy: 0.7748 - val_loss: 0.6998 - val_cont_out_loss: 0.0889 - val_cat_out_loss: 0.6108 - val_cat_out_sparse_categorical_accuracy: 0.7748\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.6856 - cont_out_loss: 0.0833 - cat_out_loss: 0.6023 - cat_out_sparse_categorical_accuracy: 0.7803 - val_loss: 0.6530 - val_cont_out_loss: 0.0607 - val_cat_out_loss: 0.5923 - val_cat_out_sparse_categorical_accuracy: 0.7862\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.6742 - cont_out_loss: 0.0817 - cat_out_loss: 0.5924 - cat_out_sparse_categorical_accuracy: 0.7847 - val_loss: 0.6854 - val_cont_out_loss: 0.0930 - val_cat_out_loss: 0.5924 - val_cat_out_sparse_categorical_accuracy: 0.7855\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.6625 - cont_out_loss: 0.0808 - cat_out_loss: 0.5817 - cat_out_sparse_categorical_accuracy: 0.7900 - val_loss: 0.6751 - val_cont_out_loss: 0.0945 - val_cat_out_loss: 0.5806 - val_cat_out_sparse_categorical_accuracy: 0.7901\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.6522 - cont_out_loss: 0.0797 - cat_out_loss: 0.5725 - cat_out_sparse_categorical_accuracy: 0.7932 - val_loss: 0.6484 - val_cont_out_loss: 0.0765 - val_cat_out_loss: 0.5719 - val_cat_out_sparse_categorical_accuracy: 0.7967\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.6425 - cont_out_loss: 0.0783 - cat_out_loss: 0.5642 - cat_out_sparse_categorical_accuracy: 0.7983 - val_loss: 0.6234 - val_cont_out_loss: 0.0593 - val_cat_out_loss: 0.5641 - val_cat_out_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.6342 - cont_out_loss: 0.0772 - cat_out_loss: 0.5570 - cat_out_sparse_categorical_accuracy: 0.8002 - val_loss: 0.6293 - val_cont_out_loss: 0.0715 - val_cat_out_loss: 0.5578 - val_cat_out_sparse_categorical_accuracy: 0.7945\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.6261 - cont_out_loss: 0.0767 - cat_out_loss: 0.5494 - cat_out_sparse_categorical_accuracy: 0.8044 - val_loss: 0.6418 - val_cont_out_loss: 0.0800 - val_cat_out_loss: 0.5619 - val_cat_out_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.6177 - cont_out_loss: 0.0752 - cat_out_loss: 0.5424 - cat_out_sparse_categorical_accuracy: 0.8061 - val_loss: 0.6345 - val_cont_out_loss: 0.0835 - val_cat_out_loss: 0.5509 - val_cat_out_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.6119 - cont_out_loss: 0.0753 - cat_out_loss: 0.5366 - cat_out_sparse_categorical_accuracy: 0.8087 - val_loss: 0.6082 - val_cont_out_loss: 0.0435 - val_cat_out_loss: 0.5647 - val_cat_out_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.6071 - cont_out_loss: 0.0739 - cat_out_loss: 0.5332 - cat_out_sparse_categorical_accuracy: 0.8102 - val_loss: 0.5918 - val_cont_out_loss: 0.0500 - val_cat_out_loss: 0.5418 - val_cat_out_sparse_categorical_accuracy: 0.8052\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.6004 - cont_out_loss: 0.0735 - cat_out_loss: 0.5270 - cat_out_sparse_categorical_accuracy: 0.8131 - val_loss: 0.6057 - val_cont_out_loss: 0.0655 - val_cat_out_loss: 0.5402 - val_cat_out_sparse_categorical_accuracy: 0.8107\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.5948 - cont_out_loss: 0.0726 - cat_out_loss: 0.5222 - cat_out_sparse_categorical_accuracy: 0.8139 - val_loss: 0.6225 - val_cont_out_loss: 0.0793 - val_cat_out_loss: 0.5432 - val_cat_out_sparse_categorical_accuracy: 0.8045\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.5896 - cont_out_loss: 0.0717 - cat_out_loss: 0.5180 - cat_out_sparse_categorical_accuracy: 0.8152 - val_loss: 0.5968 - val_cont_out_loss: 0.0674 - val_cat_out_loss: 0.5293 - val_cat_out_sparse_categorical_accuracy: 0.8120\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.5844 - cont_out_loss: 0.0711 - cat_out_loss: 0.5133 - cat_out_sparse_categorical_accuracy: 0.8176 - val_loss: 0.6257 - val_cont_out_loss: 0.0939 - val_cat_out_loss: 0.5318 - val_cat_out_sparse_categorical_accuracy: 0.8082\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.5787 - cont_out_loss: 0.0705 - cat_out_loss: 0.5082 - cat_out_sparse_categorical_accuracy: 0.8194 - val_loss: 0.6044 - val_cont_out_loss: 0.0770 - val_cat_out_loss: 0.5274 - val_cat_out_sparse_categorical_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5739 - cont_out_loss: 0.0694 - cat_out_loss: 0.5045 - cat_out_sparse_categorical_accuracy: 0.8226 - val_loss: 0.5790 - val_cont_out_loss: 0.0636 - val_cat_out_loss: 0.5154 - val_cat_out_sparse_categorical_accuracy: 0.8143\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5700 - cont_out_loss: 0.0691 - cat_out_loss: 0.5009 - cat_out_sparse_categorical_accuracy: 0.8228 - val_loss: 0.5756 - val_cont_out_loss: 0.0645 - val_cat_out_loss: 0.5111 - val_cat_out_sparse_categorical_accuracy: 0.8175\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5655 - cont_out_loss: 0.0688 - cat_out_loss: 0.4967 - cat_out_sparse_categorical_accuracy: 0.8240 - val_loss: 0.5896 - val_cont_out_loss: 0.0791 - val_cat_out_loss: 0.5105 - val_cat_out_sparse_categorical_accuracy: 0.8160\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5611 - cont_out_loss: 0.0682 - cat_out_loss: 0.4930 - cat_out_sparse_categorical_accuracy: 0.8255 - val_loss: 0.5892 - val_cont_out_loss: 0.0760 - val_cat_out_loss: 0.5132 - val_cat_out_sparse_categorical_accuracy: 0.8183\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.5581 - cont_out_loss: 0.0675 - cat_out_loss: 0.4907 - cat_out_sparse_categorical_accuracy: 0.8267 - val_loss: 0.5919 - val_cont_out_loss: 0.0840 - val_cat_out_loss: 0.5079 - val_cat_out_sparse_categorical_accuracy: 0.8205\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.5536 - cont_out_loss: 0.0671 - cat_out_loss: 0.4866 - cat_out_sparse_categorical_accuracy: 0.8304 - val_loss: 0.5580 - val_cont_out_loss: 0.0572 - val_cat_out_loss: 0.5008 - val_cat_out_sparse_categorical_accuracy: 0.8209\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5498 - cont_out_loss: 0.0666 - cat_out_loss: 0.4832 - cat_out_sparse_categorical_accuracy: 0.8310 - val_loss: 0.5735 - val_cont_out_loss: 0.0774 - val_cat_out_loss: 0.4961 - val_cat_out_sparse_categorical_accuracy: 0.8255\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.5469 - cont_out_loss: 0.0660 - cat_out_loss: 0.4809 - cat_out_sparse_categorical_accuracy: 0.8306 - val_loss: 0.5703 - val_cont_out_loss: 0.0696 - val_cat_out_loss: 0.5007 - val_cat_out_sparse_categorical_accuracy: 0.8185\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.5435 - cont_out_loss: 0.0659 - cat_out_loss: 0.4776 - cat_out_sparse_categorical_accuracy: 0.8318 - val_loss: 0.5595 - val_cont_out_loss: 0.0654 - val_cat_out_loss: 0.4941 - val_cat_out_sparse_categorical_accuracy: 0.8275\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.5404 - cont_out_loss: 0.0653 - cat_out_loss: 0.4751 - cat_out_sparse_categorical_accuracy: 0.8324 - val_loss: 0.5969 - val_cont_out_loss: 0.1041 - val_cat_out_loss: 0.4927 - val_cat_out_sparse_categorical_accuracy: 0.8225\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.5369 - cont_out_loss: 0.0645 - cat_out_loss: 0.4724 - cat_out_sparse_categorical_accuracy: 0.8339 - val_loss: 0.5510 - val_cont_out_loss: 0.0579 - val_cat_out_loss: 0.4932 - val_cat_out_sparse_categorical_accuracy: 0.8232\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5343 - cont_out_loss: 0.0639 - cat_out_loss: 0.4704 - cat_out_sparse_categorical_accuracy: 0.8336 - val_loss: 0.5576 - val_cont_out_loss: 0.0688 - val_cat_out_loss: 0.4888 - val_cat_out_sparse_categorical_accuracy: 0.8238\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.5324 - cont_out_loss: 0.0637 - cat_out_loss: 0.4686 - cat_out_sparse_categorical_accuracy: 0.8343 - val_loss: 0.5648 - val_cont_out_loss: 0.0839 - val_cat_out_loss: 0.4810 - val_cat_out_sparse_categorical_accuracy: 0.8293\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.5274 - cont_out_loss: 0.0626 - cat_out_loss: 0.4648 - cat_out_sparse_categorical_accuracy: 0.8360 - val_loss: 0.5482 - val_cont_out_loss: 0.0644 - val_cat_out_loss: 0.4838 - val_cat_out_sparse_categorical_accuracy: 0.8278\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.5247 - cont_out_loss: 0.0618 - cat_out_loss: 0.4630 - cat_out_sparse_categorical_accuracy: 0.8374 - val_loss: 0.5443 - val_cont_out_loss: 0.0572 - val_cat_out_loss: 0.4871 - val_cat_out_sparse_categorical_accuracy: 0.8269\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.5200 - cont_out_loss: 0.0604 - cat_out_loss: 0.4596 - cat_out_sparse_categorical_accuracy: 0.8388 - val_loss: 0.5343 - val_cont_out_loss: 0.0616 - val_cat_out_loss: 0.4728 - val_cat_out_sparse_categorical_accuracy: 0.8324\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.5176 - cont_out_loss: 0.0593 - cat_out_loss: 0.4583 - cat_out_sparse_categorical_accuracy: 0.8384 - val_loss: 0.5291 - val_cont_out_loss: 0.0456 - val_cat_out_loss: 0.4834 - val_cat_out_sparse_categorical_accuracy: 0.8271\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.5145 - cont_out_loss: 0.0585 - cat_out_loss: 0.4560 - cat_out_sparse_categorical_accuracy: 0.8380 - val_loss: 0.5640 - val_cont_out_loss: 0.0880 - val_cat_out_loss: 0.4760 - val_cat_out_sparse_categorical_accuracy: 0.8270\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.5123 - cont_out_loss: 0.0583 - cat_out_loss: 0.4540 - cat_out_sparse_categorical_accuracy: 0.8395 - val_loss: 0.5398 - val_cont_out_loss: 0.0606 - val_cat_out_loss: 0.4792 - val_cat_out_sparse_categorical_accuracy: 0.8283\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.5092 - cont_out_loss: 0.0577 - cat_out_loss: 0.4515 - cat_out_sparse_categorical_accuracy: 0.8410 - val_loss: 0.5377 - val_cont_out_loss: 0.0618 - val_cat_out_loss: 0.4759 - val_cat_out_sparse_categorical_accuracy: 0.8316\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.5067 - cont_out_loss: 0.0575 - cat_out_loss: 0.4492 - cat_out_sparse_categorical_accuracy: 0.8420 - val_loss: 0.5353 - val_cont_out_loss: 0.0483 - val_cat_out_loss: 0.4870 - val_cat_out_sparse_categorical_accuracy: 0.8254\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.5049 - cont_out_loss: 0.0570 - cat_out_loss: 0.4478 - cat_out_sparse_categorical_accuracy: 0.8413 - val_loss: 0.5345 - val_cont_out_loss: 0.0646 - val_cat_out_loss: 0.4699 - val_cat_out_sparse_categorical_accuracy: 0.8311\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.5025 - cont_out_loss: 0.0565 - cat_out_loss: 0.4460 - cat_out_sparse_categorical_accuracy: 0.8433 - val_loss: 0.5672 - val_cont_out_loss: 0.0639 - val_cat_out_loss: 0.5033 - val_cat_out_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.5004 - cont_out_loss: 0.0566 - cat_out_loss: 0.4438 - cat_out_sparse_categorical_accuracy: 0.8441 - val_loss: 0.5394 - val_cont_out_loss: 0.0669 - val_cat_out_loss: 0.4725 - val_cat_out_sparse_categorical_accuracy: 0.8336\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.4984 - cont_out_loss: 0.0562 - cat_out_loss: 0.4422 - cat_out_sparse_categorical_accuracy: 0.8440 - val_loss: 0.5452 - val_cont_out_loss: 0.0651 - val_cat_out_loss: 0.4802 - val_cat_out_sparse_categorical_accuracy: 0.8268\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.4961 - cont_out_loss: 0.0557 - cat_out_loss: 0.4404 - cat_out_sparse_categorical_accuracy: 0.8453 - val_loss: 0.5412 - val_cont_out_loss: 0.0589 - val_cat_out_loss: 0.4823 - val_cat_out_sparse_categorical_accuracy: 0.8282\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.4925 - cont_out_loss: 0.0554 - cat_out_loss: 0.4371 - cat_out_sparse_categorical_accuracy: 0.8462 - val_loss: 0.5350 - val_cont_out_loss: 0.0606 - val_cat_out_loss: 0.4744 - val_cat_out_sparse_categorical_accuracy: 0.8334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4903 - cont_out_loss: 0.0554 - cat_out_loss: 0.4349 - cat_out_sparse_categorical_accuracy: 0.8474 - val_loss: 0.5169 - val_cont_out_loss: 0.0435 - val_cat_out_loss: 0.4734 - val_cat_out_sparse_categorical_accuracy: 0.8320\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4901 - cont_out_loss: 0.0550 - cat_out_loss: 0.4352 - cat_out_sparse_categorical_accuracy: 0.8460 - val_loss: 0.5115 - val_cont_out_loss: 0.0448 - val_cat_out_loss: 0.4666 - val_cat_out_sparse_categorical_accuracy: 0.8336\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4886 - cont_out_loss: 0.0547 - cat_out_loss: 0.4340 - cat_out_sparse_categorical_accuracy: 0.8460 - val_loss: 0.5011 - val_cont_out_loss: 0.0412 - val_cat_out_loss: 0.4599 - val_cat_out_sparse_categorical_accuracy: 0.8368\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4865 - cont_out_loss: 0.0551 - cat_out_loss: 0.4314 - cat_out_sparse_categorical_accuracy: 0.8482 - val_loss: 0.5055 - val_cont_out_loss: 0.0441 - val_cat_out_loss: 0.4614 - val_cat_out_sparse_categorical_accuracy: 0.8381\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4844 - cont_out_loss: 0.0546 - cat_out_loss: 0.4298 - cat_out_sparse_categorical_accuracy: 0.8479 - val_loss: 0.5214 - val_cont_out_loss: 0.0540 - val_cat_out_loss: 0.4674 - val_cat_out_sparse_categorical_accuracy: 0.8332\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4812 - cont_out_loss: 0.0542 - cat_out_loss: 0.4270 - cat_out_sparse_categorical_accuracy: 0.8491 - val_loss: 0.5132 - val_cont_out_loss: 0.0512 - val_cat_out_loss: 0.4620 - val_cat_out_sparse_categorical_accuracy: 0.8357\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4795 - cont_out_loss: 0.0535 - cat_out_loss: 0.4260 - cat_out_sparse_categorical_accuracy: 0.8495 - val_loss: 0.5233 - val_cont_out_loss: 0.0582 - val_cat_out_loss: 0.4651 - val_cat_out_sparse_categorical_accuracy: 0.8337\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4793 - cont_out_loss: 0.0542 - cat_out_loss: 0.4251 - cat_out_sparse_categorical_accuracy: 0.8500 - val_loss: 0.5105 - val_cont_out_loss: 0.0440 - val_cat_out_loss: 0.4665 - val_cat_out_sparse_categorical_accuracy: 0.8338\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4765 - cont_out_loss: 0.0532 - cat_out_loss: 0.4233 - cat_out_sparse_categorical_accuracy: 0.8508 - val_loss: 0.5389 - val_cont_out_loss: 0.0537 - val_cat_out_loss: 0.4852 - val_cat_out_sparse_categorical_accuracy: 0.8232\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.4742 - cont_out_loss: 0.0531 - cat_out_loss: 0.4211 - cat_out_sparse_categorical_accuracy: 0.8512 - val_loss: 0.5039 - val_cont_out_loss: 0.0426 - val_cat_out_loss: 0.4613 - val_cat_out_sparse_categorical_accuracy: 0.8350\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.4732 - cont_out_loss: 0.0535 - cat_out_loss: 0.4197 - cat_out_sparse_categorical_accuracy: 0.8525 - val_loss: 0.5308 - val_cont_out_loss: 0.0679 - val_cat_out_loss: 0.4630 - val_cat_out_sparse_categorical_accuracy: 0.8356\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.4709 - cont_out_loss: 0.0532 - cat_out_loss: 0.4177 - cat_out_sparse_categorical_accuracy: 0.8526 - val_loss: 0.5150 - val_cont_out_loss: 0.0486 - val_cat_out_loss: 0.4664 - val_cat_out_sparse_categorical_accuracy: 0.8351\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.4695 - cont_out_loss: 0.0524 - cat_out_loss: 0.4170 - cat_out_sparse_categorical_accuracy: 0.8536 - val_loss: 0.5365 - val_cont_out_loss: 0.0731 - val_cat_out_loss: 0.4633 - val_cat_out_sparse_categorical_accuracy: 0.8335\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.4673 - cont_out_loss: 0.0524 - cat_out_loss: 0.4149 - cat_out_sparse_categorical_accuracy: 0.8532 - val_loss: 0.4986 - val_cont_out_loss: 0.0440 - val_cat_out_loss: 0.4545 - val_cat_out_sparse_categorical_accuracy: 0.8386\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.4670 - cont_out_loss: 0.0521 - cat_out_loss: 0.4150 - cat_out_sparse_categorical_accuracy: 0.8524 - val_loss: 0.5242 - val_cont_out_loss: 0.0630 - val_cat_out_loss: 0.4613 - val_cat_out_sparse_categorical_accuracy: 0.8367\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.4646 - cont_out_loss: 0.0522 - cat_out_loss: 0.4124 - cat_out_sparse_categorical_accuracy: 0.8552 - val_loss: 0.5033 - val_cont_out_loss: 0.0533 - val_cat_out_loss: 0.4500 - val_cat_out_sparse_categorical_accuracy: 0.8398\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.4640 - cont_out_loss: 0.0523 - cat_out_loss: 0.4117 - cat_out_sparse_categorical_accuracy: 0.8530 - val_loss: 0.5137 - val_cont_out_loss: 0.0632 - val_cat_out_loss: 0.4505 - val_cat_out_sparse_categorical_accuracy: 0.8387\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.4615 - cont_out_loss: 0.0517 - cat_out_loss: 0.4098 - cat_out_sparse_categorical_accuracy: 0.8540 - val_loss: 0.5099 - val_cont_out_loss: 0.0470 - val_cat_out_loss: 0.4629 - val_cat_out_sparse_categorical_accuracy: 0.8352\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.4616 - cont_out_loss: 0.0519 - cat_out_loss: 0.4097 - cat_out_sparse_categorical_accuracy: 0.8541 - val_loss: 0.5363 - val_cont_out_loss: 0.0706 - val_cat_out_loss: 0.4658 - val_cat_out_sparse_categorical_accuracy: 0.8323\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.4588 - cont_out_loss: 0.0517 - cat_out_loss: 0.4070 - cat_out_sparse_categorical_accuracy: 0.8574 - val_loss: 0.4996 - val_cont_out_loss: 0.0435 - val_cat_out_loss: 0.4561 - val_cat_out_sparse_categorical_accuracy: 0.8376\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.4571 - cont_out_loss: 0.0515 - cat_out_loss: 0.4057 - cat_out_sparse_categorical_accuracy: 0.8564 - val_loss: 0.5311 - val_cont_out_loss: 0.0609 - val_cat_out_loss: 0.4702 - val_cat_out_sparse_categorical_accuracy: 0.8306\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.4561 - cont_out_loss: 0.0513 - cat_out_loss: 0.4049 - cat_out_sparse_categorical_accuracy: 0.8572 - val_loss: 0.5291 - val_cont_out_loss: 0.0780 - val_cat_out_loss: 0.4511 - val_cat_out_sparse_categorical_accuracy: 0.8409\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.4538 - cont_out_loss: 0.0510 - cat_out_loss: 0.4028 - cat_out_sparse_categorical_accuracy: 0.8562 - val_loss: 0.5288 - val_cont_out_loss: 0.0635 - val_cat_out_loss: 0.4653 - val_cat_out_sparse_categorical_accuracy: 0.8353\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4530 - cont_out_loss: 0.0506 - cat_out_loss: 0.4024 - cat_out_sparse_categorical_accuracy: 0.8568 - val_loss: 0.5147 - val_cont_out_loss: 0.0561 - val_cat_out_loss: 0.4586 - val_cat_out_sparse_categorical_accuracy: 0.8399\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4522 - cont_out_loss: 0.0508 - cat_out_loss: 0.4013 - cat_out_sparse_categorical_accuracy: 0.8579 - val_loss: 0.4972 - val_cont_out_loss: 0.0516 - val_cat_out_loss: 0.4456 - val_cat_out_sparse_categorical_accuracy: 0.8410\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4512 - cont_out_loss: 0.0512 - cat_out_loss: 0.3999 - cat_out_sparse_categorical_accuracy: 0.8578 - val_loss: 0.5245 - val_cont_out_loss: 0.0541 - val_cat_out_loss: 0.4704 - val_cat_out_sparse_categorical_accuracy: 0.8301\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4504 - cont_out_loss: 0.0510 - cat_out_loss: 0.3994 - cat_out_sparse_categorical_accuracy: 0.8585 - val_loss: 0.5045 - val_cont_out_loss: 0.0492 - val_cat_out_loss: 0.4552 - val_cat_out_sparse_categorical_accuracy: 0.8360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4480 - cont_out_loss: 0.0511 - cat_out_loss: 0.3969 - cat_out_sparse_categorical_accuracy: 0.8597 - val_loss: 0.5064 - val_cont_out_loss: 0.0622 - val_cat_out_loss: 0.4442 - val_cat_out_sparse_categorical_accuracy: 0.8431\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4463 - cont_out_loss: 0.0504 - cat_out_loss: 0.3959 - cat_out_sparse_categorical_accuracy: 0.8596 - val_loss: 0.4948 - val_cont_out_loss: 0.0423 - val_cat_out_loss: 0.4524 - val_cat_out_sparse_categorical_accuracy: 0.8393\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.4464 - cont_out_loss: 0.0504 - cat_out_loss: 0.3960 - cat_out_sparse_categorical_accuracy: 0.8592 - val_loss: 0.5076 - val_cont_out_loss: 0.0500 - val_cat_out_loss: 0.4576 - val_cat_out_sparse_categorical_accuracy: 0.8368\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.4450 - cont_out_loss: 0.0504 - cat_out_loss: 0.3946 - cat_out_sparse_categorical_accuracy: 0.8594 - val_loss: 0.4908 - val_cont_out_loss: 0.0471 - val_cat_out_loss: 0.4437 - val_cat_out_sparse_categorical_accuracy: 0.8431\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.4432 - cont_out_loss: 0.0501 - cat_out_loss: 0.3931 - cat_out_sparse_categorical_accuracy: 0.8593 - val_loss: 0.5216 - val_cont_out_loss: 0.0631 - val_cat_out_loss: 0.4584 - val_cat_out_sparse_categorical_accuracy: 0.8368\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.4422 - cont_out_loss: 0.0501 - cat_out_loss: 0.3921 - cat_out_sparse_categorical_accuracy: 0.8614 - val_loss: 0.4980 - val_cont_out_loss: 0.0484 - val_cat_out_loss: 0.4497 - val_cat_out_sparse_categorical_accuracy: 0.8388\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4409 - cont_out_loss: 0.0499 - cat_out_loss: 0.3910 - cat_out_sparse_categorical_accuracy: 0.8601 - val_loss: 0.5086 - val_cont_out_loss: 0.0576 - val_cat_out_loss: 0.4511 - val_cat_out_sparse_categorical_accuracy: 0.8381\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4389 - cont_out_loss: 0.0494 - cat_out_loss: 0.3895 - cat_out_sparse_categorical_accuracy: 0.8622 - val_loss: 0.5111 - val_cont_out_loss: 0.0545 - val_cat_out_loss: 0.4566 - val_cat_out_sparse_categorical_accuracy: 0.8376\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4387 - cont_out_loss: 0.0497 - cat_out_loss: 0.3890 - cat_out_sparse_categorical_accuracy: 0.8615 - val_loss: 0.4968 - val_cont_out_loss: 0.0508 - val_cat_out_loss: 0.4460 - val_cat_out_sparse_categorical_accuracy: 0.8429\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4367 - cont_out_loss: 0.0498 - cat_out_loss: 0.3869 - cat_out_sparse_categorical_accuracy: 0.8626 - val_loss: 0.5010 - val_cont_out_loss: 0.0460 - val_cat_out_loss: 0.4550 - val_cat_out_sparse_categorical_accuracy: 0.8373\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4357 - cont_out_loss: 0.0495 - cat_out_loss: 0.3862 - cat_out_sparse_categorical_accuracy: 0.8611 - val_loss: 0.4883 - val_cont_out_loss: 0.0372 - val_cat_out_loss: 0.4511 - val_cat_out_sparse_categorical_accuracy: 0.8374\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4353 - cont_out_loss: 0.0496 - cat_out_loss: 0.3857 - cat_out_sparse_categorical_accuracy: 0.8627 - val_loss: 0.4960 - val_cont_out_loss: 0.0561 - val_cat_out_loss: 0.4400 - val_cat_out_sparse_categorical_accuracy: 0.8431\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4342 - cont_out_loss: 0.0499 - cat_out_loss: 0.3842 - cat_out_sparse_categorical_accuracy: 0.8644 - val_loss: 0.4834 - val_cont_out_loss: 0.0435 - val_cat_out_loss: 0.4399 - val_cat_out_sparse_categorical_accuracy: 0.8450\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4327 - cont_out_loss: 0.0493 - cat_out_loss: 0.3834 - cat_out_sparse_categorical_accuracy: 0.8630 - val_loss: 0.5056 - val_cont_out_loss: 0.0545 - val_cat_out_loss: 0.4511 - val_cat_out_sparse_categorical_accuracy: 0.8402\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4313 - cont_out_loss: 0.0490 - cat_out_loss: 0.3823 - cat_out_sparse_categorical_accuracy: 0.8639 - val_loss: 0.4901 - val_cont_out_loss: 0.0430 - val_cat_out_loss: 0.4470 - val_cat_out_sparse_categorical_accuracy: 0.8403\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4299 - cont_out_loss: 0.0491 - cat_out_loss: 0.3808 - cat_out_sparse_categorical_accuracy: 0.8644 - val_loss: 0.4729 - val_cont_out_loss: 0.0329 - val_cat_out_loss: 0.4400 - val_cat_out_sparse_categorical_accuracy: 0.8403\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4287 - cont_out_loss: 0.0490 - cat_out_loss: 0.3797 - cat_out_sparse_categorical_accuracy: 0.8655 - val_loss: 0.4986 - val_cont_out_loss: 0.0494 - val_cat_out_loss: 0.4492 - val_cat_out_sparse_categorical_accuracy: 0.8386\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4278 - cont_out_loss: 0.0490 - cat_out_loss: 0.3788 - cat_out_sparse_categorical_accuracy: 0.8662 - val_loss: 0.4970 - val_cont_out_loss: 0.0445 - val_cat_out_loss: 0.4526 - val_cat_out_sparse_categorical_accuracy: 0.8393\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4258 - cont_out_loss: 0.0488 - cat_out_loss: 0.3770 - cat_out_sparse_categorical_accuracy: 0.8660 - val_loss: 0.5135 - val_cont_out_loss: 0.0690 - val_cat_out_loss: 0.4445 - val_cat_out_sparse_categorical_accuracy: 0.8411\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([X1_train,X2_train], {'cont_out': y_train, 'cat_out': z_train},\n",
    "                    validation_data=([X1_val, X2_val], {'cont_out': y_val, 'cat_out': z_val}),\n",
    "                    epochs=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "# 카드 서비스 카테고리 맞추는 게 더 중요 : 일단 이것만 보자\n",
    "loss_ax.plot(hist.history['cat_out_loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_cat_out_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(hist.history['cat_out_sparse_categorical_accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_cat_out_sparse_categorical_accuracy'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./data/20210426.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./data/20210426.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_df = pd.read_csv('./data/20210421_card_meta_features_normalized.csv') #, index=False)\n",
    "card_df = card_df.set_index('상품번호')\n",
    "\n",
    "# 모델 입력용 array\n",
    "ftr_array = card_df.to_numpy()\n",
    "ftrs = {x:ftr_array[idx] for idx, x in enumerate(card_df.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서비스이름 참조용\n",
    "svc_dict = {idx:svc for idx, svc in enumerate(card_df.columns[1:])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카드이름 참조용\n",
    "name_dict = pickle.load(open('./data/20210420_cardname_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상품명을 보고 아래와 같이 구분할 수 잇도록\n",
    "skypass = {'AFJAPT', 'ALMA1V', 'ALNA7M', 'ALPAPE', 'ALRB01', 'ALSB7E', 'ALWBPA', 'BFBBQ0'}\n",
    "asiana = {'AFJAPU', 'ALNA7N', 'ALPAPF', 'ALRB02', 'ALSB7F', 'ALWBPB', 'BFAB8J'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00058676 0.21024997 0.07632519 0.04489779 0.40158544 0.31306627\n",
      " 0.15340232 0.26202177 0.11713819 0.08084938 0.52892685 0.32629134\n",
      " 0.39012722 0.11546162 0.10538639 0.2493409  0.07999183 0.39227965\n",
      " 0.22596689 0.08137287 0.09697775 0.36896356 0.39044971 0.04622434\n",
      " 0.5       ] [0.0015683  0.43160428 0.08526979 0.053367   1.         0.73425958\n",
      " 0.30486663 0.57223939 0.12448629 0.08592107 0.97917232 0.66915711\n",
      " 0.63818257 0.12270455 0.11199729 0.63238692 0.08500973 1.\n",
      " 0.48831117 0.08647741 0.10306118 0.91492223 0.85887431 0.05137886\n",
      " 0.5       ]\n",
      "SELECTED ['신한카드 Always FAN', '신한카드 The CLASSIC-L', '신한카드 B.Big(삑)']\n",
      "SEL AIRS ['', '', '']\n",
      "SVC IDS 요식 온라인쇼핑\n",
      "CPU times: user 9.06 ms, sys: 1.58 ms, total: 10.6 ms\n",
      "Wall time: 8.81 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>항공구분</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BEKBCU</td>\n",
       "      <td>신한카드 All Pass</td>\n",
       "      <td>0.595521</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BIABE0</td>\n",
       "      <td>신한카드 Deep Oil</td>\n",
       "      <td>0.550785</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BEAB7G</td>\n",
       "      <td>신세계 신한카드</td>\n",
       "      <td>0.543254</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>AQCAFX</td>\n",
       "      <td>신한카드 미래설계</td>\n",
       "      <td>0.533208</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFAB8J</td>\n",
       "      <td>아시아나 신한카드 Air 1.5</td>\n",
       "      <td>0.529057</td>\n",
       "      <td>아시아나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>AWABHH</td>\n",
       "      <td>신한카드 주거래 신용</td>\n",
       "      <td>0.491802</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BOACF4</td>\n",
       "      <td>신한카드 혼디모앙</td>\n",
       "      <td>0.491794</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BELBD7</td>\n",
       "      <td>신한카드 EV</td>\n",
       "      <td>0.478566</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BELBX9</td>\n",
       "      <td>알뜰교통 신한카드</td>\n",
       "      <td>0.478566</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ALWBPB</td>\n",
       "      <td>신한카드 The BEST+</td>\n",
       "      <td>0.476352</td>\n",
       "      <td>아시아나</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               name     score  항공구분\n",
       "4   BEKBCU      신한카드 All Pass  0.595521      \n",
       "10  BIABE0      신한카드 Deep Oil  0.550785      \n",
       "55  BEAB7G           신세계 신한카드  0.543254      \n",
       "48  AQCAFX          신한카드 미래설계  0.533208      \n",
       "3   BFAB8J  아시아나 신한카드 Air 1.5  0.529057  아시아나\n",
       "51  AWABHH        신한카드 주거래 신용  0.491802      \n",
       "52  BOACF4          신한카드 혼디모앙  0.491794      \n",
       "16  BELBD7            신한카드 EV  0.478566      \n",
       "47  BELBX9          알뜰교통 신한카드  0.478566      \n",
       "33  ALWBPB     신한카드 The BEST+  0.476352  아시아나"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_sel = 3 #np.random.randint(6)\n",
    "if n_sel > 0:\n",
    "    sel_ids = card_df.sample(n_sel).index\n",
    "    sel_ftrs = [ftrs.get(i) for i in sel_ids]\n",
    "    X1, X2 = np.mean(sel_ftrs, axis=0), np.max(sel_ftrs, axis=0)\n",
    "    print(X1, X2)\n",
    "else:\n",
    "    sel_ids = []\n",
    "    X1, X2 = np.array([0]*24), np.array([0]*24)\n",
    "sel_names = [name_dict.get(i) for i in sel_ids]\n",
    "pred = model.predict([pd.DataFrame(X1).T, pd.DataFrame(X2).T])\n",
    "A = np.concatenate((pred[0][0], pred[1][0]))\n",
    "print('SELECTED', sel_names)\n",
    "print('SEL AIRS', ['아시아나' if x in asiana else '대한항공' if x in skypass else '' for x in sel_ids])\n",
    "print('SVC IDS', svc_dict.get(np.argmax(X1)), svc_dict.get(np.argmax(X2)))\n",
    "ret = []\n",
    "for B in ftrs:\n",
    "    if B not in sel_ids:\n",
    "        ret.append([B, name_dict.get(B), cos_sim(A, ftrs.get(B))])\n",
    "ret = pd.DataFrame(ret, columns=['id', 'name', 'score']).sort_values(by='score', ascending=False)\n",
    "ret['항공구분'] = ret['id'].map(lambda x: '아시아나' if x in asiana else '대한항공' if x in skypass else '')\n",
    "ret.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'cards': [\"BOACF4\", \"BOAC6A\", \"BNBC47\", \"AXAAZE\", \"BPAC88\"], 'actions': [0, 0, 0, 1, 0]},\n",
    "{'cards': [\"BECB97\", \"BOAC6A\", \"BNBC47\", \"AXAAZE\", \"BPAC88\"], 'actions': [1, 0, 0, 0, 0]},\n",
    "{'cards': [\"AXDBMR\", \"BOAC6A\", \"BCBBLO\", \"AZAAZW\", \"AXAAZE\"], 'actions': [0, 0, 0, 1, 0]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK_TO_SERVE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ftr_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-c9e4f1372454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mftr_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ftr_ids' is not defined"
     ]
    }
   ],
   "source": [
    "ftr_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(X=[]):\n",
    "    A, B = X\n",
    "    return np.matmul(A, B.T)/(norm(A)*norm(B, axis=1))\n",
    "    #args = np.argsort(mat)[-rank:]\n",
    "    #return mat[args], ftr_ids[args]\n",
    "\n",
    "    \n",
    "def make_prediction_merge_3_results(data):\n",
    "    ret = []\n",
    "    for actions in data:\n",
    "        #tmp = actions['cards'] * \n",
    "        input = [ftrs.get(actions['cards'][idx[0]]) for idx in np.argwhere(actions['actions'])]\n",
    "        X1, X2 = np.mean(input, axis=0), np.max(input, axis=0)\n",
    "        pred = model.predict([pd.DataFrame(X1).T, pd.DataFrame(X2).T])\n",
    "        A = np.concatenate(pred, axis=1)[0]\n",
    "        mat = cos_sim([A, ftr_array])\n",
    "        args = np.argsort(mat)[-RANK_TO_SERVE:]\n",
    "        ret.append([mat[args], ftr_ids[args]])\n",
    "    _score, _ids = np.concatenate(ret, axis=1)\n",
    "    recom = []\n",
    "    for idx in reversed(np.argsort(_score)):\n",
    "        if _ids[idx] in recom: continue\n",
    "        recom.append(_ids[idx])\n",
    "        if len(recom) == 5: break\n",
    "    return recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BFAB8J', 'BA7AQ7', 'BECB97', 'AVAATJ', 'AYAAZF']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction_merge_3_results(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "def cos_sim(X=[], rank=5):\n",
    "    A, B = X\n",
    "    mat = np.matmul(A, B.T)/(norm(A)*norm(B, axis=1))\n",
    "    args = np.argsort(mat)[-rank:]\n",
    "    return mat[args], cids[args]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_ids = np.array(list(ftrs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.50294624, 0.51197379, 0.53540871, 0.53602806, 0.59256905]),\n",
       " array(['ALSB7F', 'ALNA7N', 'ALWBPB', 'ALRB02', 'BFAB8J'], dtype='<U6'))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim([A, ftr_array], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = cos_sim([A, ftr_array], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2 = cos_sim([A, ftr_array], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score, _ids = np.concatenate([rec1, rec2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom = []\n",
    "for idx in reversed(np.argsort(_score)):\n",
    "    if _ids[idx] in recom: continue\n",
    "    recom.append(_ids[idx])\n",
    "    if len(recom) == 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BA7A3X', 'ALZCCY', 'ALSB7F', 'BOAC6A', 'ALSB7E']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALSB7E', 'ALSB7F', 'ALZCCY', 'BA7A3X', 'BOAC6A'}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(_ids[np.argsort(_score)[-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003080075253058428\n",
      "0.008230530134489017\n",
      "0.4733445185303833\n",
      "0.5925690513903296\n",
      "0.27880390704162045\n",
      "0.2743271380183205\n",
      "0.32707535725183895\n",
      "0.3177190095506084\n",
      "0.30100340040480766\n",
      "0.2704806325940677\n",
      "0.274531871926937\n",
      "0.3193842289821952\n",
      "0.26444724591085733\n",
      "0.3156603025188148\n",
      "0.3657842778005116\n",
      "0.2798789277780118\n",
      "0.3193795465513295\n",
      "0.3468649151636613\n",
      "0.35223482781224935\n",
      "0.27177187991705093\n",
      "0.31658167325536557\n",
      "0.3717744277581451\n",
      "0.2693745443176762\n",
      "0.33901404447151817\n",
      "0.3089729023751842\n",
      "0.356194319068925\n",
      "0.2749652169907308\n",
      "0.27384954274461215\n",
      "0.2619725075000436\n",
      "0.3516333541598955\n",
      "0.29276552035022185\n",
      "0.2744165119225144\n",
      "0.040260439137780525\n",
      "0.5029462427680799\n",
      "0.00973244750088741\n",
      "0.5354087134497282\n",
      "0.009668626383311637\n",
      "0.2651623373409527\n",
      "0.002783996275726132\n",
      "0.5360280588926102\n",
      "0.0043083823080378595\n",
      "0.4497296134549152\n",
      "0.008075085390730678\n",
      "0.5119737932728596\n",
      "0.2886612289362047\n",
      "0.3458818912015659\n",
      "0.37034552862376185\n",
      "0.31586733859389904\n",
      "0.30927539984173885\n",
      "0.27963244953021726\n",
      "0.35223482781224935\n",
      "0.2829872920264247\n",
      "0.31660700260216496\n",
      "0.31660700260216496\n",
      "0.32894633972497855\n",
      "0.26982959564616454\n",
      "0.3248157473891471\n",
      "0.29064966877890497\n",
      "0.27035446007935043\n",
      "0.3093990959313467\n"
     ]
    }
   ],
   "source": [
    "for B in ftrs:\n",
    "    print(cos_sim(A, ftrs.get(B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BFBBQ0'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.36375215, 1.89323434, 2.14110632, 1.69110019, 1.80123339,\n",
       "       1.83040484, 1.53535207, 1.58272282, 1.66543869, 1.84974442,\n",
       "       1.87992646, 1.56922567, 1.89731033, 1.58890159, 1.37475515,\n",
       "       1.79189661, 1.56922565, 1.44837422, 1.42576257, 1.90455518,\n",
       "       1.59289469, 1.35403363, 1.915339  , 1.48213121, 1.62215268,\n",
       "       1.41324351, 1.82370699, 1.84076914, 1.93610032, 1.43120638,\n",
       "       1.71633156, 1.82894418, 1.88645619, 2.13511521, 1.60734031,\n",
       "       1.8930248 , 1.88485673, 1.95004215, 1.57999228, 1.86985978,\n",
       "       2.00221042, 2.2380451 , 1.7042831 , 1.97600123, 1.77611373,\n",
       "       1.45359077, 1.36054105, 1.59777519, 1.62353858, 1.79477486,\n",
       "       1.42576257, 1.77298547, 1.59239085, 1.59239085, 1.53172345,\n",
       "       1.90297381, 1.54894742, 1.72719217, 1.87335279, 1.62626348])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm([ftrs.get(x) for x in ftrs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BFAB8J</th>\n",
       "      <td>0.592569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA7AQ7</th>\n",
       "      <td>0.585944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BECB97</th>\n",
       "      <td>0.551590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVAATJ</th>\n",
       "      <td>0.546737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AYAAZF</th>\n",
       "      <td>0.544018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCBBLO</th>\n",
       "      <td>0.541107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALRB02</th>\n",
       "      <td>0.536028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALWBPB</th>\n",
       "      <td>0.535409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXAAZE</th>\n",
       "      <td>0.532508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALNA7N</th>\n",
       "      <td>0.511974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFJAPT</th>\n",
       "      <td>0.504254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALSB7F</th>\n",
       "      <td>0.502946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFJAPU</th>\n",
       "      <td>0.473345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZAAZW</th>\n",
       "      <td>0.462309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALMA1V</th>\n",
       "      <td>0.451177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALPAPF</th>\n",
       "      <td>0.449730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALMA1U</th>\n",
       "      <td>0.436084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEC03A</th>\n",
       "      <td>0.427288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BJABE3</th>\n",
       "      <td>0.418007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOACF4</th>\n",
       "      <td>0.393581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFA00A</th>\n",
       "      <td>0.387204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA69LH</th>\n",
       "      <td>0.371774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALOBFQ</th>\n",
       "      <td>0.370346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNBC47</th>\n",
       "      <td>0.365784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BJCBLP</th>\n",
       "      <td>0.361136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPAC88</th>\n",
       "      <td>0.356194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELBX9</th>\n",
       "      <td>0.352235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELBD7</th>\n",
       "      <td>0.352235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA7A3X</th>\n",
       "      <td>0.351633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDAB6R</th>\n",
       "      <td>0.346865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALXC6E</th>\n",
       "      <td>0.345882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALZCCY</th>\n",
       "      <td>0.339014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWABHH</th>\n",
       "      <td>0.328946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATAAMK</th>\n",
       "      <td>0.327075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCCBYF</th>\n",
       "      <td>0.324816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLABSJ</th>\n",
       "      <td>0.319384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLBBSK</th>\n",
       "      <td>0.319380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APB9YL</th>\n",
       "      <td>0.317719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AOBCB7</th>\n",
       "      <td>0.316607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AOBCB6</th>\n",
       "      <td>0.316607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALQARY</th>\n",
       "      <td>0.316582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCECA3</th>\n",
       "      <td>0.315867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXDBMR</th>\n",
       "      <td>0.315660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOAC6A</th>\n",
       "      <td>0.309399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXGC75</th>\n",
       "      <td>0.309275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUAARH</th>\n",
       "      <td>0.308973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMABZ2</th>\n",
       "      <td>0.301003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALNA7L</th>\n",
       "      <td>0.288661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AQCAFX</th>\n",
       "      <td>0.282987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEKBCU</th>\n",
       "      <td>0.278804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXCB5L</th>\n",
       "      <td>0.274327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEAB7G</th>\n",
       "      <td>0.270354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIABE0</th>\n",
       "      <td>0.264447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCAAZX</th>\n",
       "      <td>0.261973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFBBQ0</th>\n",
       "      <td>0.114348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALSB7E</th>\n",
       "      <td>0.095752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALWBPA</th>\n",
       "      <td>0.090436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALRB01</th>\n",
       "      <td>0.086884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALNA7M</th>\n",
       "      <td>0.066829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALPAPE</th>\n",
       "      <td>0.043018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "id              \n",
       "BFAB8J  0.592569\n",
       "BA7AQ7  0.585944\n",
       "BECB97  0.551590\n",
       "AVAATJ  0.546737\n",
       "AYAAZF  0.544018\n",
       "BCBBLO  0.541107\n",
       "ALRB02  0.536028\n",
       "ALWBPB  0.535409\n",
       "AXAAZE  0.532508\n",
       "ALNA7N  0.511974\n",
       "AFJAPT  0.504254\n",
       "ALSB7F  0.502946\n",
       "AFJAPU  0.473345\n",
       "AZAAZW  0.462309\n",
       "ALMA1V  0.451177\n",
       "ALPAPF  0.449730\n",
       "ALMA1U  0.436084\n",
       "AEC03A  0.427288\n",
       "BJABE3  0.418007\n",
       "BOACF4  0.393581\n",
       "AFA00A  0.387204\n",
       "BA69LH  0.371774\n",
       "ALOBFQ  0.370346\n",
       "BNBC47  0.365784\n",
       "BJCBLP  0.361136\n",
       "BPAC88  0.356194\n",
       "BELBX9  0.352235\n",
       "BELBD7  0.352235\n",
       "BA7A3X  0.351633\n",
       "BDAB6R  0.346865\n",
       "ALXC6E  0.345882\n",
       "ALZCCY  0.339014\n",
       "AWABHH  0.328946\n",
       "ATAAMK  0.327075\n",
       "BCCBYF  0.324816\n",
       "BLABSJ  0.319384\n",
       "BLBBSK  0.319380\n",
       "APB9YL  0.317719\n",
       "AOBCB7  0.316607\n",
       "AOBCB6  0.316607\n",
       "ALQARY  0.316582\n",
       "BCECA3  0.315867\n",
       "AXDBMR  0.315660\n",
       "BOAC6A  0.309399\n",
       "AXGC75  0.309275\n",
       "AUAARH  0.308973\n",
       "BMABZ2  0.301003\n",
       "ALNA7L  0.288661\n",
       "AQCAFX  0.282987\n",
       "BEKBCU  0.278804\n",
       "AXCB5L  0.274327\n",
       "BEAB7G  0.270354\n",
       "BIABE0  0.264447\n",
       "BCAAZX  0.261973\n",
       "BFBBQ0  0.114348\n",
       "ALSB7E  0.095752\n",
       "ALWBPA  0.090436\n",
       "ALRB01  0.086884\n",
       "ALNA7M  0.066829\n",
       "ALPAPE  0.043018"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = []\n",
    "for actions in data:\n",
    "    #tmp = actions['cards'] * \n",
    "    input = [ftrs.get(actions['cards'][idx[0]]) for idx in np.argwhere(actions['actions'])]\n",
    "    X1, X2 = np.mean(input, axis=0), np.max(input, axis=0)\n",
    "    pred = model.predict([pd.DataFrame(X1).T, pd.DataFrame(X2).T])\n",
    "    A = np.concatenate(pred, axis=1)[0]\n",
    "    for B in ftrs:\n",
    "        ret.append([B, cos_sim(A, ftrs.get(B))])\n",
    "pd.DataFrame(ret, columns=['id', 'score']).sort_values(by='score', ascending=False).groupby(by='id').first().sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.01809402e-02, 3.08656674e-08, 1.48526489e-08, 1.09290006e-07,\n",
       "       8.99158069e-04, 4.28418900e-07, 4.39814798e-08, 1.84040971e-07,\n",
       "       1.84111268e-08, 3.11524627e-06, 1.95840003e-05, 1.68958138e-07,\n",
       "       3.96354594e-09, 9.94396448e-01, 5.21828724e-07, 1.26981661e-07,\n",
       "       6.82276095e-07, 2.71059753e-06, 5.52937036e-06, 5.05811606e-08,\n",
       "       6.00921112e-06, 1.24004248e-06, 4.58224630e-03, 1.41440069e-06,\n",
       "       8.02434879e-05], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFBBQ0\n"
     ]
    }
   ],
   "source": [
    "for B in ftrs:\n",
    "    print(B)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.01809402e-02, 3.08656674e-08, 1.48526489e-08, 1.09290006e-07,\n",
       "        8.99158069e-04, 4.28418900e-07, 4.39814798e-08, 1.84040971e-07,\n",
       "        1.84111268e-08, 3.11524627e-06, 1.95840003e-05, 1.68958138e-07,\n",
       "        3.96354594e-09, 9.94396448e-01, 5.21828724e-07, 1.26981661e-07,\n",
       "        6.82276095e-07, 2.71059753e-06, 5.52937036e-06, 5.05811606e-08,\n",
       "        6.00921112e-06, 1.24004248e-06, 4.58224630e-03, 1.41440069e-06,\n",
       "        8.02434879e-05]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.04018094]], dtype=float32),\n",
       " array([[3.08656674e-08, 1.48526489e-08, 1.09290006e-07, 8.99158069e-04,\n",
       "         4.28418900e-07, 4.39814798e-08, 1.84040971e-07, 1.84111268e-08,\n",
       "         3.11524627e-06, 1.95840003e-05, 1.68958138e-07, 3.96354594e-09,\n",
       "         9.94396448e-01, 5.21828724e-07, 1.26981661e-07, 6.82276095e-07,\n",
       "         2.71059753e-06, 5.52937036e-06, 5.05811606e-08, 6.00921112e-06,\n",
       "         1.24004248e-06, 4.58224630e-03, 1.41440069e-06, 8.02434879e-05]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
